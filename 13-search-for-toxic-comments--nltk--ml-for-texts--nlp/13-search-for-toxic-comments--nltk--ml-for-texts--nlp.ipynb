{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск токсичных комментариев (с NLTK)\n",
    "\n",
    "<h2> (Тема №13: Машинное обучение для текстов) <a class=\"tocSkip\"> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1. Содержание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Содержание](#1)\n",
    "\n",
    "[2. Описание проекта](#2)\n",
    "\n",
    "*    [2.1. Цель проекта](#21)\n",
    "*    [2.2. Задачи проекта](#22)\n",
    "*    [2.3. Описание данных](#23)\n",
    "*    [2.4. План работы](#24)\n",
    "\n",
    "[3. Подготовка данных](#3)\n",
    "\n",
    "*    [3.1. Изучение данных](#31)\n",
    "*    [3.2. Очистка данных](#32)\n",
    "*    [3.3. Лемматизация `WordNetLemmatizer`](#33)\n",
    "*    [3.4. Лемматизация `WordNetLemmatizer` с *POS*-тегами](#34)\n",
    "*    [3.5. Вывод](#35)\n",
    "\n",
    "[4. Обучение моделей](#4)\n",
    "\n",
    "*    [4.1. Разделение данных на выборки](#41)\n",
    "*    [4.2. `LogisticRegression`](#42)\n",
    "\n",
    "    *    [4.2.1. `model_lr`](#421)\n",
    "    *    [4.2.2. `model_lr_pos`](#422)\n",
    "    \n",
    "*    [4.3. `DecisionTreeClassifier`](#43)\n",
    "\n",
    "    *    [4.3.1. `model_dt`](#431)\n",
    "    *    [4.3.2. `model_dt_pos`](#432)\n",
    "\n",
    "*    [4.4. `LGBMClassifier`](#44)\n",
    "\n",
    "    *    [4.4.1. `model_lgbm50`](#441)\n",
    "    *    [4.4.2. `model_lgbm50_pos`](#442)\n",
    "    *    [4.4.3. `model_lgbm500`](#443)\n",
    "    *    [4.4.4. `model_lgbm500_pos`](#444)\n",
    "\n",
    "*    [4.5. Сравнение моделей](#45)\n",
    "*    [4.6. Вывод](#46)\n",
    "\n",
    "[5. Тестирование лучшей модели](#5)\n",
    "\n",
    "*    [5.1. Качество модели](#51)\n",
    "*    [5.2. Вывод](#52)\n",
    "\n",
    "[6. Общий вывод](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 2. Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"21\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.1. Цель проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести исследование с целью построения модели машинного обучения, которая поможет классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"22\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.2. Задачи проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим поставленную в проекте задачу **с помощью библиотеки *NLTK***.\n",
    "\n",
    "1. Изучить данные.\n",
    "2. Подготовить данные.\n",
    "3. Лемматизировать данные.\n",
    "4. Построить и обучить модели.\n",
    "5. Протестировать лучшую модель.\n",
    "6. Написать общий вывод.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"23\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.3. Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`.\n",
    "\n",
    "Столбец `text` в нём содержит текст комментария, а `toxic` — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"24\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.4. План работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Изучим данные.\n",
    "2. Очистим комментарии **с помощью библиотеки *NLTK***: переведём буквы в нижний регистр, оставим только латиницу, удалим стоп-слова. \n",
    "3. Лемматизируем комментарии без учёта части речи (без *POS*-тегов) **с помощью библиотеки *NLTK***.\n",
    "4. Лемматизируем комментарии с учётом части речи (с *POS*-тегами) **с помощью библиотеки *NLTK***.\n",
    "5. Разделим данные на обучающую и тестовую выборки для данных без *POS*-тегов и с *POS*-тегами.\n",
    "6. Рассчитаем величину *TF-IDF* для данных без *POS*-тегов и с *POS*-тегами.\n",
    "7. Обучим восемь моделей (`LogisticRegression`, `DecisionTreeClassifier` и `LGBMClassifier` с количеством деревьев `n_estimators`=50 и `n_estimators`=500) для данных без *POS*-тегов и с *POS*-тегами.\n",
    "8. Сравненим модели.\n",
    "9. Протестируем лучшую модель и напишем вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 3. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.corpus import stopwords as nltk_stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "RANDOM_STATE = 12345\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"31\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.1. Изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    try:\n",
    "        data = pd.read_csv(r'C:/Users/lorad/OneDrive/Documents/Моя папка/Data Science/Курсы/'\n",
    "                            'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "                            '13. Машинное обучение для текстов/toxic_comments.csv')\n",
    "    except:\n",
    "        try:\n",
    "            data = pd.read_csv(r'D:/Юлия/Data Science/Курсы/'\n",
    "                                'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "                                '13. Машинное обучение для текстов/toxic_comments.csv')\n",
    "        except:\n",
    "            data = pd.read_csv('https://docs.google.com/spreadsheets/d/e/'\n",
    "            '2PACX-1vQ59JmNL2DruMdFkZoOga-GFUBVFTSgDnVt4Pt7SErYdQQ7hHrTSzRaBHYMhpwa_K4xlnKs_8zrW6di/'\n",
    "                               'pub?gid=1802044232&single=true&output=csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153116</th>\n",
       "      <td>153273</td>\n",
       "      <td>That's the one about someone blowing up her ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158581</th>\n",
       "      <td>158740</td>\n",
       "      <td>Just so you don't think I'm going behind your ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27513</th>\n",
       "      <td>27550</td>\n",
       "      <td>|decline=Indeed. :==( o )</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58027</th>\n",
       "      <td>58091</td>\n",
       "      <td>Quit vandalizing the pages or you will be bloc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158010</th>\n",
       "      <td>158169</td>\n",
       "      <td>Citation one through four also imo need removi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "153116      153273  That's the one about someone blowing up her ki...      0\n",
       "158581      158740  Just so you don't think I'm going behind your ...      0\n",
       "27513        27550                          |decline=Indeed. :==( o )      0\n",
       "58027        58091  Quit vandalizing the pages or you will be bloc...      0\n",
       "158010      158169  Citation one through four also imo need removi...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет имеет большой размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159292, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic\n",
       "count  159292.000000  159292.000000\n",
       "mean    79725.697242       0.101612\n",
       "std     46028.837471       0.302139\n",
       "min         0.000000       0.000000\n",
       "25%     39872.750000       0.000000\n",
       "50%     79721.500000       0.000000\n",
       "75%    119573.250000       0.000000\n",
       "max    159450.000000       1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим наличие явных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем количество классов в таргете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдается сильный дисбаланс классов в таргете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"32\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.2. Очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем решать поставленную в проекте задачу **с помощью библиотеки *NLTK*** (англ. *Natural Language Toolkit*, «инструментарий естественного языка») — ведущая платформа для создания NLP-программ на Python.\n",
    "\n",
    "Напишем функцию `clear_text()`, которая очищает комментарии: переводит буквы в нижний регистр, оставляет только латиницу, удаляет стоп-слова (`stop_words`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    stop_words = set(nltk_stopwords.words('english'))\n",
    "    # переведём в нижний регистр\n",
    "    text = text.lower()\n",
    "    # оставим только латиницу\n",
    "    word_list = re.sub(r\"[^a-z ]\", ' ', text).split()\n",
    "    # удалим stop_words\n",
    "    word_notstop_list = [w for w in word_list if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(word_notstop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в датасет новый признак `clean_text` с очищенными комментариями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 36.2 s\n",
      "Wall time: 36.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['clean_text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем полученный датасет `data` с новым признаком `clean_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117340</th>\n",
       "      <td>117439</td>\n",
       "      <td>REDIRECT Talk:Absolutely (sketch show)</td>\n",
       "      <td>0</td>\n",
       "      <td>redirect talk absolutely sketch show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108857</th>\n",
       "      <td>108954</td>\n",
       "      <td>Menopause and spotting \\n\\nHi Invertzoo. ,\\nAs...</td>\n",
       "      <td>0</td>\n",
       "      <td>menopause spotting hi invertzoo stated woman s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120663</th>\n",
       "      <td>120768</td>\n",
       "      <td>Silver lining \\n\\nGo to  and see if your brows...</td>\n",
       "      <td>0</td>\n",
       "      <td>silver lining go see browser passes test ie ff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23468</th>\n",
       "      <td>23488</td>\n",
       "      <td>\"::::\"\"Projectively extended real numbers\"\" is...</td>\n",
       "      <td>0</td>\n",
       "      <td>projectively extended real numbers fine chance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111902</th>\n",
       "      <td>111999</td>\n",
       "      <td>Please cease adding unsourced information; you...</td>\n",
       "      <td>0</td>\n",
       "      <td>please cease adding unsourced information bloc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "117340      117439             REDIRECT Talk:Absolutely (sketch show)      0   \n",
       "108857      108954  Menopause and spotting \\n\\nHi Invertzoo. ,\\nAs...      0   \n",
       "120663      120768  Silver lining \\n\\nGo to  and see if your brows...      0   \n",
       "23468        23488  \"::::\"\"Projectively extended real numbers\"\" is...      0   \n",
       "111902      111999  Please cease adding unsourced information; you...      0   \n",
       "\n",
       "                                               clean_text  \n",
       "117340               redirect talk absolutely sketch show  \n",
       "108857  menopause spotting hi invertzoo stated woman s...  \n",
       "120663  silver lining go see browser passes test ie ff...  \n",
       "23468   projectively extended real numbers fine chance...  \n",
       "111902  please cease adding unsourced information bloc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"33\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.3. Лемматизация `WordNetLemmatizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wordnet* – это большая, свободно распространяемая и общедоступная лексическая база данных для английского языка с целью установления структурированных семантических отношений между словами. Для того, чтобы лемматизировать комментарии, нужно создать экземпляр `WordNetLemmatizer` и вызвать функцию `lemmatize()` для одного слова.\n",
    "\n",
    "Лемматизируем комментарии без учёта части речи (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    # создадим объект класса для лемматизации\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    \n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в датасет новый признак `wnl_text` с комментариями, лемматизированными без *POS*-тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "время выполнения лемматизации: 18 s\n",
      "CPU times: total: 18.1 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "data['wnl_text'] = data['clean_text'].apply(lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(f'время выполнения лемматизации: {data_lemm_time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"34\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.4. Лемматизация `WordNetLemmatizer` с *POS*-тегами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем комментарии с учётом части речи (с *POS*-тегами) **с помощью библиотеки *NLTK***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    # сопоставим POS-тег с первым символом, \n",
    "    # который принимает функция lemmatize()\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    \n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag_lemm_text(text):\n",
    "    # создадим объект класса для лемматизации с учетом POS-тегов\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([\n",
    "        lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list\n",
    "    ])\n",
    "    \n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в датасет новый признак `wnlpostag_text` с комментариями, лемматизированными с *POS*-тегами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "время выполнения лемматизации с POS-тегами: 3270 s\n",
      "CPU times: total: 50min 43s\n",
      "Wall time: 54min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "data['wnlpostag_text'] = data['clean_text'].apply(postag_lemm_text)\n",
    "data_lemm_pos_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(f'время выполнения лемматизации с POS-тегами: {data_lemm_pos_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata.to_csv('data_lemm2.csv', index=False)\\ndata = pd.read_csv('data_lemm2.csv')\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# промежуточно сохраняем файл с очищенными и лемматизированными комментариями\n",
    "'''\n",
    "data.to_csv('data_lemm2.csv', index=False)\n",
    "data = pd.read_csv('data_lemm2.csv')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем полученный датасет `data` с новыми признаками `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>151541</th>\n",
       "      <th>20160</th>\n",
       "      <th>116955</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>151697</td>\n",
       "      <td>20180</td>\n",
       "      <td>117054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>Something must be done!</td>\n",
       "      <td>Well thanks for all your Bundeswehr Heer addit...</td>\n",
       "      <td>\"\\n\\nI removed it because it was unsourced. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_text</th>\n",
       "      <td>something must done</td>\n",
       "      <td>well thanks bundeswehr heer additions division...</td>\n",
       "      <td>removed unsourced think article neutral point ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnl_text</th>\n",
       "      <td>something must done</td>\n",
       "      <td>well thanks bundeswehr heer addition division ...</td>\n",
       "      <td>removed unsourced think article neutral point ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnlpostag_text</th>\n",
       "      <td>something must do</td>\n",
       "      <td>well thanks bundeswehr heer addition division ...</td>\n",
       "      <td>remove unsourced think article neutral point v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 151541  \\\n",
       "Unnamed: 0                       151697   \n",
       "text            Something must be done!   \n",
       "toxic                                 0   \n",
       "clean_text          something must done   \n",
       "wnl_text            something must done   \n",
       "wnlpostag_text        something must do   \n",
       "\n",
       "                                                           20160   \\\n",
       "Unnamed: 0                                                  20180   \n",
       "text            Well thanks for all your Bundeswehr Heer addit...   \n",
       "toxic                                                           0   \n",
       "clean_text      well thanks bundeswehr heer additions division...   \n",
       "wnl_text        well thanks bundeswehr heer addition division ...   \n",
       "wnlpostag_text  well thanks bundeswehr heer addition division ...   \n",
       "\n",
       "                                                           116955  \n",
       "Unnamed: 0                                                 117054  \n",
       "text            \"\\n\\nI removed it because it was unsourced. I ...  \n",
       "toxic                                                           0  \n",
       "clean_text      removed unsourced think article neutral point ...  \n",
       "wnl_text        removed unsourced think article neutral point ...  \n",
       "wnlpostag_text  remove unsourced think article neutral point v...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(3).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"35\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.5. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе [**Подготовка данных**](#3.-Подготовка-данных) были выполнены следующие задачи:\n",
    "1. данные изучены;\n",
    "2. комментарии очищены: буквы переведены в нижний регистр, оставлена только латиница, стоп-слова удалены; \n",
    "3. комментарии лемматизированы без учёта части речи (без *POS*-тегов);\n",
    "4. комментарии лемматизированы с учётом части речи (с *POS*-тегами).\n",
    "\n",
    "\n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "1. пропусков в данных нет;\n",
    "2. типы данных соответствуют требованиям для последующей очистки и лемматизации комментариев;\n",
    "3. датасет имеет большой размер: содержит 159 292 текстовых комментария;\n",
    "4. явных дубликатов нет;\n",
    "5. наблюдается сильный дисбаланс классов в таргете.\n",
    "\n",
    "**В проекте решается задача бинарной классификации.**\n",
    "\n",
    "Таким образом, данные подготовлены для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 4. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"41\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.1. Разделение данных на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметры для кроссвалидации: `n_splits` - количество фолдов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки для обоих признаков `wnl_text` и `wnlpostag_text` в соотношении 4:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    data['wnl_text'], data['toxic'].values, test_size=TEST_SIZE, stratify=data['toxic'].values, \n",
    "    shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_pos, features_test_pos, target_train_pos, target_test_pos = train_test_split(\n",
    "    data['wnlpostag_text'], data['toxic'].values, test_size=TEST_SIZE, stratify=data['toxic'].values, \n",
    "    shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка важности слова определяется величиной *TF-IDF* (от англ. *term frequency*, «частота терма, или слова»; *inverse document frequency*, «обратная частота документа, или текста»). То есть *TF* отвечает за количество упоминаний слова в отдельном тексте, а *IDF* отражает частоту его употребления во всём корпусе.\n",
    "\n",
    "Рассчитаем *TF-IDF* для обоих признаков `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf_pos = TfidfVectorizer()\n",
    "tf_idf_train_pos = count_tf_idf_pos.fit_transform(features_train_pos)\n",
    "tf_idf_test_pos = count_tf_idf_pos.transform(features_test_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обоих признаков `wnl_text` и `wnlpostag_text`обучим восемь моделей (`LogisticRegression`, `DecisionTreeClassifier` и `LGBMClassifier` с количеством деревьев `n_estimators`=50 и `n_estimators`=500). Для обучения моделей используем функцию `cross_val_score()`. Учтём баланс классов в модели с помощью параметра `class_weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"42\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.2. `LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **логистической регрессии *Logistic Regression*** для обоих признаков `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"421\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.2.1. `model_lr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **логистической регрессии *Logistic Regression*** для признака `wnl_text` (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.753\n",
      "модель: LogisticRegression\n",
      "данные: wnl_text\n",
      "время работы модели: 5 s\n",
      "CPU times: total: 20.7 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lr = LogisticRegression(solver='liblinear', \n",
    "                              class_weight='balanced', \n",
    "                              random_state=RANDOM_STATE)\n",
    "\n",
    "model_lr.mod = 'model_lr'\n",
    "model_lr.name = 'LogisticRegression'\n",
    "model_lr.data = 'wnl_text'\n",
    "model_lr.f1 = cross_val_score(model_lr,\n",
    "                              tf_idf_train, \n",
    "                              target_train, \n",
    "                              cv=kfold, \n",
    "                              scoring='f1')\n",
    "\n",
    "model_lr.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lr.f1.mean()))\n",
    "print('модель:', model_lr.name)\n",
    "print('данные:', model_lr.data)\n",
    "print(f'время работы модели: {model_lr.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.753\n",
    "- модель: `LogisticRegression` \n",
    "- данные: `wnl_text`\n",
    "- время работы модели: 5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"422\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.2.2. `model_lr_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **логистической регрессии *Logistic Regression*** для признака `wnlpostag_text` (с *POS*-тегами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.752\n",
      "модель: LogisticRegression\n",
      "данные: wnlpostag_text\n",
      "время работы модели: 5 s\n",
      "CPU times: total: 21.6 s\n",
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lr_pos = LogisticRegression(solver='liblinear', \n",
    "                                  class_weight='balanced', \n",
    "                                  random_state=RANDOM_STATE)\n",
    "\n",
    "model_lr_pos.mod = 'model_lr_pos'\n",
    "model_lr_pos.name = 'LogisticRegression'\n",
    "model_lr_pos.data = 'wnlpostag_text'\n",
    "model_lr_pos.f1 = cross_val_score(model_lr_pos, \n",
    "                                  tf_idf_train_pos, \n",
    "                                  target_train_pos, \n",
    "                                  cv=kfold, \n",
    "                                  scoring='f1')\n",
    "\n",
    "model_lr_pos.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lr_pos.f1.mean()))\n",
    "print('модель:', model_lr_pos.name)\n",
    "print('данные:', model_lr_pos.data)\n",
    "print(f'время работы модели: {model_lr_pos.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.752\n",
    "- модель: `LogisticRegression` \n",
    "- данные: `wnlpostag_text` \n",
    "- время работы модели: 5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"43\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.3. `DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **дерева решений *Decision Tree*** для обоих признаков `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"431\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.3.1. `model_dt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **дерева решений *Decision Tree*** для признака `wnl_text` (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.618\n",
      "модель: DecisionTreeClassifier\n",
      "данные: wnl_text\n",
      "время работы модели: 85 s\n",
      "CPU times: total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_dt = DecisionTreeClassifier(max_depth=15, \n",
    "                                  class_weight='balanced', \n",
    "                                  random_state=RANDOM_STATE)\n",
    "\n",
    "model_dt.mod = 'model_dt'\n",
    "model_dt.name = 'DecisionTreeClassifier'\n",
    "model_dt.data = 'wnl_text'\n",
    "model_dt.f1 = cross_val_score(model_dt, \n",
    "                              tf_idf_train, \n",
    "                              target_train, \n",
    "                              cv=kfold, \n",
    "                              scoring='f1')\n",
    "\n",
    "model_dt.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_dt.f1.mean()))\n",
    "print('модель:', model_dt.name)\n",
    "print('данные:', model_dt.data)\n",
    "print(f'время работы модели: {model_dt.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.618\n",
    "- модель: `DecisionTreeClassifier`\n",
    "- глубина дерева: `max_depth` = 15\n",
    "- данные: `wnl_text`\n",
    "- время работы модели: 85 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"432\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.3.2. `model_dt_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **дерева решений *Decision Tree*** для признака `wnlpostag_text` (с *POS*-тегами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.625\n",
      "модель: DecisionTreeClassifier\n",
      "данные: wnlpostag_text\n",
      "время работы модели: 85 s\n",
      "CPU times: total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_dt_pos = DecisionTreeClassifier(max_depth=15,\n",
    "                                      class_weight='balanced', \n",
    "                                      random_state=RANDOM_STATE)\n",
    "\n",
    "model_dt_pos.mod = 'model_dt_pos'\n",
    "model_dt_pos.name = 'DecisionTreeClassifier'\n",
    "model_dt_pos.data = 'wnlpostag_text'\n",
    "model_dt_pos.f1 = cross_val_score(model_dt_pos, \n",
    "                                  tf_idf_train_pos, \n",
    "                                  target_train_pos, \n",
    "                                  cv=kfold, \n",
    "                                  scoring='f1')\n",
    "\n",
    "model_dt_pos.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_dt_pos.f1.mean()))\n",
    "print('модель:', model_dt_pos.name)\n",
    "print('данные:', model_dt_pos.data)\n",
    "print(f'время работы модели: {model_dt_pos.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.625\n",
    "- модель: `DecisionTreeClassifier`\n",
    "- глубина дерева: `max_depth` = 15\n",
    "- данные: `wnlpostag_text` \n",
    "- время работы модели: 85 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"44\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.4. `LGBMClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=50 и `n_estimators`=500 для обоих признаков `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"441\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.4.1. `model_lgbm50`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=50 для признака `wnl_text` (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.724\n",
      "модель: LGBMClassifier 50\n",
      "данные: wnl_text\n",
      "время работы модели: 42 s\n",
      "CPU times: total: 4min 23s\n",
      "Wall time: 42.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lgbm50 = LGBMClassifier(n_estimators=50,\n",
    "                              max_depth=10,\n",
    "                              learning_rate=0.15,\n",
    "                              class_weight='balanced', \n",
    "                              boosting_type='gbdt', \n",
    "                              objective='binary', \n",
    "                              random_state=RANDOM_STATE)\n",
    "\n",
    "model_lgbm50.mod = 'model_lgbm50'\n",
    "model_lgbm50.name = 'LGBMClassifier 50'\n",
    "model_lgbm50.data = 'wnl_text'\n",
    "model_lgbm50.f1 = cross_val_score(model_lgbm50, \n",
    "                                  tf_idf_train, \n",
    "                                  target_train, \n",
    "                                  cv=kfold, \n",
    "                                  scoring='f1')\n",
    "\n",
    "model_lgbm50.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lgbm50.f1.mean()))\n",
    "print('модель:', model_lgbm50.name)\n",
    "print('данные:', model_lgbm50.data)\n",
    "print(f'время работы модели: {model_lgbm50.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.724\n",
    "- модель: `LGBMClassifier`\n",
    "- количество деревьев: `n_estimators` = 50\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnl_text`  \n",
    "- время работы модели: 42 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"442\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.4.2. `model_lgbm50_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=50 для признака `wnlpostag_text` (с *POS*-тегами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.730\n",
      "модель: LGBMClassifier 50\n",
      "данные: wnlpostag_text\n",
      "время работы модели: 40 s\n",
      "CPU times: total: 4min 2s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lgbm50_pos = LGBMClassifier(n_estimators=50,\n",
    "                                  max_depth=10,\n",
    "                                  learning_rate=0.15,\n",
    "                                  class_weight='balanced', \n",
    "                                  boosting_type='gbdt', \n",
    "                                  objective='binary', \n",
    "                                  random_state=RANDOM_STATE)\n",
    "\n",
    "model_lgbm50_pos.mod = 'model_lgbm50_pos'\n",
    "model_lgbm50_pos.name = 'LGBMClassifier 50'\n",
    "model_lgbm50_pos.data = 'wnlpostag_text'\n",
    "model_lgbm50_pos.f1 = cross_val_score(model_lgbm50_pos, \n",
    "                                      tf_idf_train_pos, \n",
    "                                      target_train_pos, \n",
    "                                      cv=kfold, \n",
    "                                      scoring='f1')\n",
    "\n",
    "model_lgbm50_pos.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lgbm50_pos.f1.mean()))\n",
    "print('модель:', model_lgbm50_pos.name)\n",
    "print('данные:', model_lgbm50_pos.data)\n",
    "print(f'время работы модели: {model_lgbm50_pos.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.730\n",
    "- модель: `LGBMClassifier` \n",
    "- количество деревьев: `n_estimators` = 50\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnlpostag_text`  \n",
    "- время работы модели: 40 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"443\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.4.3. `model_lgbm500`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=500 для признака `wnl_text` (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.771\n",
      "модель: LGBMClassifier 500\n",
      "данные: wnl_text\n",
      "время работы модели: 179 s\n",
      "CPU times: total: 19min\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lgbm500 = LGBMClassifier(n_estimators=500,\n",
    "                               max_depth=10,\n",
    "                               learning_rate=0.15,\n",
    "                               class_weight='balanced', \n",
    "                               boosting_type='gbdt', \n",
    "                               objective='binary', \n",
    "                               random_state=RANDOM_STATE)\n",
    "\n",
    "model_lgbm500.mod = 'model_lgbm500'\n",
    "model_lgbm500.name = 'LGBMClassifier 500'\n",
    "model_lgbm500.data = 'wnl_text'\n",
    "model_lgbm500.f1 = cross_val_score(model_lgbm500, \n",
    "                                   tf_idf_train, \n",
    "                                   target_train, \n",
    "                                   cv=kfold, \n",
    "                                   scoring='f1')\n",
    "\n",
    "model_lgbm500.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lgbm500.f1.mean()))\n",
    "print('модель:', model_lgbm500.name)\n",
    "print('данные:', model_lgbm500.data)\n",
    "print(f'время работы модели: {model_lgbm500.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.771\n",
    "- модель: `LGBMClassifier` \n",
    "- количество деревьев: `n_estimators` = 500\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnl_text`  \n",
    "- время работы модели: 179 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"444\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.4.4. `model_lgbm500_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=500 для признака `wnlpostag_text` (с *POS*-тегами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.772\n",
      "модель: LGBMClassifier 500\n",
      "данные: wnlpostag_text\n",
      "время работы модели: 174 s\n",
      "CPU times: total: 17min 40s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lgbm500_pos = LGBMClassifier(n_estimators=500,\n",
    "                                   max_depth=10,\n",
    "                                   learning_rate=0.15,\n",
    "                                   class_weight='balanced', \n",
    "                                   boosting_type='gbdt', \n",
    "                                   objective='binary', \n",
    "                                   random_state=RANDOM_STATE)\n",
    "\n",
    "model_lgbm500_pos.mod = 'model_lgbm500_pos'\n",
    "model_lgbm500_pos.name = 'LGBMClassifier 500'\n",
    "model_lgbm500_pos.data = 'wnlpostag_text'\n",
    "model_lgbm500_pos.f1 = cross_val_score(model_lgbm500_pos, \n",
    "                                       tf_idf_train_pos, \n",
    "                                       target_train_pos, \n",
    "                                       cv=kfold, \n",
    "                                       scoring='f1')\n",
    "\n",
    "model_lgbm500_pos.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lgbm500_pos.f1.mean()))\n",
    "print('модель:', model_lgbm500_pos.name)\n",
    "print('данные:', model_lgbm500_pos.data)\n",
    "print(f'время работы модели: {model_lgbm500_pos.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.772\n",
    "- модель: `LGBMClassifier` \n",
    "- количество деревьев: `n_estimators` = 500\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnlpostag_text`  \n",
    "- время работы модели: 174 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"45\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.5. Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним модели и выберем лучшую, т.е. с наибольшим значением метрики *F1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_lr, model_lr_pos, model_dt, model_dt_pos, \n",
    "              model_lgbm50, model_lgbm50_pos, model_lgbm500, model_lgbm500_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cross_val_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_lr</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.752913</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lr_pos</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.752096</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_dt</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.61783</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_dt_pos</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.624639</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lgbm50</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.724338</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lgbm50_pos</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.730063</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lgbm500</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.770725</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lgbm500_pos</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.771799</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model            data  f1_score  \\\n",
       "model_lr               LogisticRegression        wnl_text  0.752913   \n",
       "model_lr_pos           LogisticRegression  wnlpostag_text  0.752096   \n",
       "model_dt           DecisionTreeClassifier        wnl_text   0.61783   \n",
       "model_dt_pos       DecisionTreeClassifier  wnlpostag_text  0.624639   \n",
       "model_lgbm50            LGBMClassifier 50        wnl_text  0.724338   \n",
       "model_lgbm50_pos        LGBMClassifier 50  wnlpostag_text  0.730063   \n",
       "model_lgbm500          LGBMClassifier 500        wnl_text  0.770725   \n",
       "model_lgbm500_pos      LGBMClassifier 500  wnlpostag_text  0.771799   \n",
       "\n",
       "                  cross_val_time  \n",
       "model_lr                       5  \n",
       "model_lr_pos                   5  \n",
       "model_dt                      85  \n",
       "model_dt_pos                  85  \n",
       "model_lgbm50                  42  \n",
       "model_lgbm50_pos              40  \n",
       "model_lgbm500                179  \n",
       "model_lgbm500_pos            174  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a={}\n",
    "for i in model_list:\n",
    "    b={}    \n",
    "    b['model']=i.name\n",
    "    b['data']=i.data\n",
    "    b['f1_score']=i.f1.mean()\n",
    "    b['cross_val_time']=i.time\n",
    "    a[i.mod] = b\n",
    "\n",
    "final_table = pd.DataFrame(a)\n",
    "\n",
    "display(final_table.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем в качестве лучшей модель **градиентного бустинга `LGBMClassifier`** `model_lgbm500_pos`, которая имеет следующее значение метрики оценки качества **на обучающей выборке**:\n",
    "\n",
    "- метрика `f1`: 0.772\n",
    "- модель: `LGBMClassifier` \n",
    "- количество деревьев: `n_estimators` = 500\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnlpostag_text`  \n",
    "- время работы модели: 174 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"46\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.6. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе [**Обучение моделей**](#4.-Обучение-моделей) были выполнены следующие задачи:\n",
    "1. Для обоих признаков `wnl_text` и `wnlpostag_text` данные разделены на обучающую и тестовую выборки.\n",
    "2. Для обоих признаков `wnl_text` и `wnlpostag_text` рассчитана величина *TF-IDF*.\n",
    "3. Для обоих признаков `wnl_text` и `wnlpostag_text`обучены восемь моделей (`LogisticRegression`, `DecisionTreeClassifier` и `LGBMClassifier` с количеством деревьев `n_estimators`=50 и `n_estimators`=500).\n",
    "4. Выведена таблица сравнения моделей.\n",
    "\n",
    "\n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "- в качестве лучшей (с наибольшим значением метрики *F1*) выбрана модель **градиентного бустинга `LGBMClassifier`** `model_lgbm500_pos`, которая имеет следующее значение метрики оценки качества **на обучающей выборке**:\n",
    "\n",
    "    - метрика `f1`: 0.772\n",
    "    - модель: `LGBMClassifier` \n",
    "    - количество деревьев: `n_estimators` = 500\n",
    "    - глубина дерева: `max_depth` = 10\n",
    "    - коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "    - данные: `wnlpostag_text`  \n",
    "    - время работы модели: 174 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 5. Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"51\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 5.1. Качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим лучшую модель **градиентного бустинга `LGBMClassifier`** `model_lgbm500_pos` **на тестовой выборке**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.775\n",
      "CPU times: total: 4min 21s\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lgbm500_pos.fit(tf_idf_train_pos, target_train_pos)\n",
    "model_lgbm500_pos.predicted = model_lgbm500_pos.predict(tf_idf_test_pos)\n",
    "model_lgbm500_pos.test_f1 = f1_score(target_test_pos, model_lgbm500_pos.predicted)\n",
    "print('f1: %.3f' %(model_lgbm500_pos.test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.775"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"52\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 5.2. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе [**Тестирование лучшей модели**](#5.-Тестирование-лучшей-модели) была протестирована лучшая модель градиентного бустинга `LGBMClassifier` `model_lgbm500_pos` с количеством деревьев `n_estimators`=500 для признака `wnlpostag_text` (с *POS*-тегами).\n",
    "   \n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "- для выбранной лучшей модели значение метрики качества ***F1 = 0.775***, что превышает 0.75, как и изначально требовалось по условию задачи проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 6. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведено исследование с целью построения модели машинного обучения, которая поможет классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Входные данные: набор данных с разметкой о токсичности правок.\n",
    "\n",
    "В ходе исследования удалось получить следующие результаты **на обучающей выборке**:\n",
    "\n",
    "\n",
    "1. **Модель `LogisticRegression`**:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи - без *POS*-тегов (для признака `wnl_text`):\n",
    "      - *F1* = 0.753\n",
    "      - время работы модели: 5 s\n",
    "   - данные, лемматизированые с учётом части речи - с *POS*-тегами (для признака `wnlpostag_text`):\n",
    "      - *F1* = 0.752\n",
    "      - время работы модели: 5 s\n",
    "\n",
    "\n",
    "2. **Модель `DecisionTreeClassifier`** с глубиной дерева `max_depth` = 15:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи - без *POS*-тегов (для признака `wnl_text`):\n",
    "      - *F1* = 0.618\n",
    "      - время работы модели: 85 s\n",
    "   - данные, лемматизированые с учётом части речи - с *POS*-тегами (для признака `wnlpostag_text`):\n",
    "      - *F1* = 0.625\n",
    "      - время работы модели: 85 s\n",
    "\n",
    "\n",
    "3. **Модель `LGBMClassifier`** с глубиной дерева `max_depth` = 10 и коэффициентом скорости обучения `learning_rate` = 0.15:\n",
    "\n",
    "- количество деревьев **`n_estimators` = 50**:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи - без *POS*-тегов (для признака `wnl_text`):\n",
    "      - *F1* = 0.724\n",
    "      - время работы модели: 42 s\n",
    "   - данные, лемматизированые с учётом части речи - с *POS*-тегами (для признака `wnlpostag_text`):\n",
    "      - *F1* = 0.730\n",
    "      - время работы модели: 40 s\n",
    "\n",
    "\n",
    "- количество деревьев **`n_estimators` = 500**:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи - без *POS*-тегов (для признака `wnl_text`):\n",
    "      - *F1* = 0.771\n",
    "      - время работы модели: 179 s\n",
    "   - данные, лемматизированые с учётом части речи - с *POS*-тегами (для признака `wnlpostag_text`):\n",
    "      - *F1* = 0.772\n",
    "      - время работы модели: 174 s\n",
    "            \n",
    "      \n",
    "Исходя из полученных результатов, можно сделать следующие **выводы**:\n",
    "\n",
    "\n",
    "1. В качестве лучшей модели выбрана:\n",
    "   - модель **градиентного бустинга `LGBMClassifier`** `model_lgbm500_pos`, которая **на тестовой выборке** имеет следующее значение метрики оценки качества:\n",
    "    - ***F1 = 0.775*** \n",
    "   \n",
    "   \n",
    "2. Для выбранной лучшей модели значение метрики качества *F1* превышает 0.75, что соответсвует изначальному требованию в условии задачи проекта.\n",
    "   \n",
    "   \n",
    "**Общие рекомендации:**\n",
    "\n",
    "Магазину можно рекомендовать использовать полученную модель **`LGBMClassifier`** в качестве инструмента, который будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2196,
    "start_time": "2023-01-26T21:17:43.084Z"
   },
   {
    "duration": 4049,
    "start_time": "2023-01-26T21:17:45.283Z"
   },
   {
    "duration": 37,
    "start_time": "2023-01-26T21:17:49.334Z"
   },
   {
    "duration": 43,
    "start_time": "2023-01-26T21:17:49.373Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-26T21:17:49.419Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-26T21:17:49.450Z"
   },
   {
    "duration": 24853,
    "start_time": "2023-01-26T21:17:49.456Z"
   },
   {
    "duration": 102,
    "start_time": "2023-01-26T21:18:14.311Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-26T21:18:14.414Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "260px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
